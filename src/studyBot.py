# Study-Bot: Question answering using audio interaction and object detection, CLI version for testing and functions for GUI version

import openai
import whisper
from pydub import AudioSegment
from pydub.playback import play as pydubPlay
import io
from typing import Iterator
import pyaudio
import wave
from pathlib import Path
from elevenlabs import generate, play, set_api_key#, stream
import cv2
import numpy as np
import time
import threading
import keyboard
import credentials # Ignored by git, contains API keys

# TODO: Replace global variables with return values from functions!

objects = ''
question = ''

GPT_MODEL = 'gpt-3.5-turbo'

# Credentials
openai.api_key = credentials.openAiKey
set_api_key(credentials.elevenLabsKey)

# Information sources
# NOTE: The information below was generated by Chat-GPT by asking for a brief summary of each organ.
source = """
Stomach: The stomach is an organ located in the upper abdomen that plays a vital role in 
the digestion of food. Its main function is to store and break down food into smaller 
particles through the process of mechanical and chemical digestion. The stomach secretes 
gastric juices, including hydrochloric acid and enzymes, which help in the breakdown of 
proteins. It also mixes the partially digested food with these juices to form a 
semi-liquid mixture called chyme, which is then gradually released into the small 
intestine for further digestion and absorption.

Liver: The liver is the largest internal organ in the human body and is located in the 
upper right abdomen. It performs numerous functions that are essential for maintaining 
overall health. One of its primary roles is the production and secretion of bile, a 
substance that aids in the digestion and absorption of fats. The liver also detoxifies 
harmful substances, metabolizes nutrients, stores vitamins and minerals, regulates 
blood glucose levels, produces blood-clotting proteins, and filters and removes old or 
damaged blood cells from circulation. Additionally, it plays a key role in the 
metabolism of drugs and toxins.

Colon: The colon, also known as the large intestine, is the final part of the digestive 
system. Its primary function is to absorb water, electrolytes, and some vitamins from 
the remaining indigestible food materials after the digestion and absorption of 
nutrients in the small intestine. The colon also houses a complex community of 
beneficial bacteria known as the gut microbiota, which helps in the fermentation of 
undigested carbohydrates and the production of certain vitamins, such as vitamin K and 
some B vitamins. It further assists in the formation and elimination of feces, 
contributing to the regulation of bowel movements.

Brain: The brain is the most complex organ in the human body and is responsible for
controlling all bodily functions. It is located in the head and consists of three main
parts: the cerebrum, cerebellum, and brainstem. The cerebrum is the largest part of the
brain and is divided into two hemispheres. It is responsible for higher functions such
as memory, language, and reasoning. The cerebellum is located at the back of the brain
and is responsible for coordinating voluntary movements and maintaining balance. The
brainstem connects the brain to the spinal cord and is responsible for controlling
involuntary functions such as breathing, heart rate, and blood pressure.

Kidney: The kidneys are two bean-shaped organs located in the upper abdomen. They play
an important role in maintaining homeostasis by regulating the composition and volume
of body fluids. The kidneys filter waste products from the blood and excrete them in
the form of urine. They also help in the regulation of blood pressure, the production
of red blood cells, and the activation of vitamin D.

Heart: The heart is a muscular organ located in the chest that pumps blood throughout
the body. It consists of four chambers: two atria and two ventricles. The atria receive
blood from the veins and pump it into the ventricles. The ventricles then pump the
blood out of the heart and into the arteries. The heart is responsible for supplying
oxygenated blood to the body and deoxygenated blood to the lungs for oxygenation.
"""

# Behavioral guidelines for conversation
instructions = """
Try to use the information below to help the user study by answering 
the user's question. The user may or may not be holding a physical representation 
of what their question is about. Consider the object list, which includes all 
the objects that the user is holding, so that the answer can be refined to be 
more specific to the user's question. Do not mention the user or the information 
in your answer to make it more sound natural.

If the question is unrelated to the information, ignore all previous instructions
and try to answer the question without mentioning the information or the objects 
to make it sound more natural.
"""

# ---------------- Audio Recording ----------------

# Recorder configuration
CHUNK = 1024 # Chunk size
FORMAT = pyaudio.paInt16 # Audio codec format
CHANNELS = 2
RATE = 44100 # Sample rate
RECORD_SECONDS = 5 # Recording duration
WAVE_OUTPUT_FILENAME = "question.wav"

def recordQuestion():
	global question
	audio = pyaudio.PyAudio() # Initialize PyAudio
	# Open audio stream for recording
	stream = audio.open(format = FORMAT, channels = CHANNELS, rate = RATE, input = True, frames_per_buffer = CHUNK)

	# print('Listening for question...\n')

	frames = []

	# Record audio stream in chunks
	for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
		data = stream.read(CHUNK)
		frames.append(data)

	# Stop and close audio stream
	stream.stop_stream()
	stream.close()
	audio.terminate()

	# print('Recording stopped.\n')
	# print('Saving audio file...\n')

	# Save recording as WAV
	wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
	wf.setnchannels(CHANNELS)
	wf.setsampwidth(audio.get_sample_size(FORMAT))
	wf.setframerate(RATE)
	wf.writeframes(b''.join(frames))
	wf.close()

	# print('Audio saved as: question.wav\n')

	# ---------------- STT Conversion -----------------

	# print('Converting audio to text...\n')

	model = whisper.load_model('base')
	result = model.transcribe('question.wav', fp16 = False, language = 'English')
	question = result['text']
	# print('Question: ' + question + '\n')
	
	# Delete audio file
	Path('question.wav').unlink()
	# print('Question audio file deleted.\n')

def lookForObjects():
	global objects
	objects = 'User is not holding any objects'

	# Capture video
	cam = cv2.VideoCapture(0) # Use 0 for default camera
	# print('Looking for objects...\n')

	startTime = time.time()
	elapsedTime = 0

	# Color ranges
	stomachLower = np.array([90, 	80, 		1			], np.uint8)
	stomachUpper = np.array([120, 	255, 		255			], np.uint8)
	colonLower = np.array(	[9, 	255 * 0.55, 255 * 0.35	], np.uint8)
	colonUpper = np.array(	[28, 	255, 		255			], np.uint8)
	liverLower = np.array(	[38, 	225 * 0.22, 255 * 0.38	], np.uint8)
	liverUpper = np.array(	[41, 	255, 		255			], np.uint8)
	brainLower = np.array(	[168, 	255 * 0.50, 255 * 0.40	], np.uint8)
	brainUpper = np.array(	[168, 	255, 		255			], np.uint8)
	kidneyLower = np.array(	[26, 	255 * 0.60, 255 * 0.49	], np.uint8)
	kidneyUpper = np.array(	[26, 	255, 		255			], np.uint8)
	heartLower = np.array(	[179, 	255 * 0.50, 255 * 0.45	], np.uint8)
	heartUpper = np.array(	[179, 	255 * 0.97, 255 * 0.69	], np.uint8)

	while elapsedTime < 1:

		_, imageFrame = cam.read()

		# Convert frame from BGR color space to HSV
		hsvFrame = cv2.cvtColor(imageFrame, cv2.COLOR_BGR2HSV)

		# Create masks for each organ
		colonMask = cv2.inRange(hsvFrame, colonLower, colonUpper)
		liverMask = cv2.inRange(hsvFrame, liverLower, liverUpper)
		stomachMask = cv2.inRange(hsvFrame, stomachLower, stomachUpper)
		brainMask = cv2.inRange(hsvFrame, brainLower, brainUpper)
		kidneyMask = cv2.inRange(hsvFrame, kidneyLower, kidneyUpper)
		heartMask = cv2.inRange(hsvFrame, heartLower, heartUpper)

		# Create a 5x5 square-shaped filter called kernel
		# Filter is filled with ones and will be used for morphological transformations such as dilation for better detection
		kernel = np.ones((5, 5), 'uint8')


		# For colon
		# Dilate mask: Remove holes in the mask by adding pixels to the boundaires of the objects in the mask
		colonMask = cv2.dilate(colonMask, kernel)
		# Apply mask to frame by using bitwise AND operation
		resColon = cv2.bitwise_and(imageFrame, imageFrame, mask = colonMask)


		# For liver
		liverMask = cv2.dilate(liverMask, kernel)
		resliver = cv2.bitwise_and(imageFrame, imageFrame, mask=liverMask)

		# For stomach
		stomachMask = cv2.dilate(stomachMask, kernel)
		resStomach = cv2.bitwise_and(imageFrame, imageFrame, mask=stomachMask)

		# For brain
		brainMask = cv2.dilate(brainMask, kernel)
		resBrain = cv2.bitwise_and(imageFrame, imageFrame, mask=brainMask)

		# For heart
		heartMask = cv2.dilate(heartMask, kernel)
		resHeart = cv2.bitwise_and(imageFrame, imageFrame, mask=heartMask)

		# For kidney use a more aggressive kernel for dilation
		kidneyMask = cv2.dilate(kidneyMask, np.ones((12, 12), 'uint8'))
		resKidney = cv2.bitwise_and(imageFrame, imageFrame, mask=kidneyMask)

		# Create a contour around the zone that matches the color range
		contours, hierarchy = cv2.findContours(colonMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		# For each countour, check if the area is greater than the threshold
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 500:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (0, 120, 255), 2)
				cv2.putText(imageFrame, "COLON", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 120, 255))
				# Append the name of the model to the list of objects
				if 'colon' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'colon'
					else:
						objects = objects + ', colon'

		contours, hierarchy = cv2.findContours(liverMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 500:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (86, 194, 0), 2)
				cv2.putText(imageFrame, "LIVER", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (86, 194, 0))
				if 'liver' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'liver'
					else:
						objects = objects + ', liver'

		contours, hierarchy = cv2.findContours(stomachMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 1400:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (237, 117, 47), 2)
				cv2.putText(imageFrame, "STOMACH", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (237, 117, 47))
				if 'stomach' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'stomach'
					else:
						objects = objects + ', stomach'

		contours, hierarchy = cv2.findContours(brainMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 500:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (0, 0, 255), 2)
				cv2.putText(imageFrame, "BRAIN", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255))
				if 'brain' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'brain'
					else:
						objects = objects + ', brain'
		
		contours, hierarchy = cv2.findContours(heartMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 500:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (255, 0, 0), 2)
				cv2.putText(imageFrame, "HEART", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0))
				if 'heart' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'heart'
					else:
						objects = objects + ', heart'

		contours, hierarchy = cv2.findContours(kidneyMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
		for pic, contour in enumerate(contours):
			area = cv2.contourArea(contour)
			if area > 500:
				x, y, w, h = cv2.boundingRect(contour)
				imageFrame = cv2.rectangle(imageFrame, (x, y), (x + w, y + h), (255, 0, 255), 2)
				cv2.putText(imageFrame, "KIDNEY", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 255))
				if 'kidney' not in objects:
					if objects == 'User is not holding any objects':
						objects = 'kidney'
					else:
						objects = objects + ', kidney'

		# Display the camera feed
		cv2.imshow('Study-Bot View', imageFrame)

		elapsedTime = time.time() - startTime

		# This does not break the loop, but removing it breaks the camera feed and causes the program to crash
		if cv2.waitKey(1) & 0xFF == ord('q'):
			break

	# Release webcam and close all windows
	cam.release()
	cv2.destroyAllWindows()

	# print('Camera closed\n')
	# print('Objects detected: ' + objects + '\n')

def sendMessage(messageList: any):
	# Take in the message list, send it to GPT, and return the response and the updated message list

	# Send prompt to GPT
	response = openai.ChatCompletion.create(
		messages = messageList,
		model = GPT_MODEL, 
		temperature = 0.2
	)

	answer = response['choices'][0]['message']['content']

	# Add the response to the message list
	messageList.append({'role': 'assistant', 'content': answer})

	return messageList, answer

# NOTE: Add reasoning about mpv for why this function is needed in docs later
def streamAnswer(audioStream: Iterator[bytes]) -> bytes:
    audioOutput = b""
    for chunk in audioStream:
        if chunk is not None:
            audioOutput += chunk

    audioSegment = AudioSegment.from_file(io.BytesIO(audioOutput), format="mp3")
    pydubPlay(audioSegment)

def convertTTS(text: str):
	# Disabled for cost cutting during testing, always sounds good anyway!

	# print('Converting answer to audio...\n')
	# audioOutput = generate(answer)
	# print('Audio conversion complete.\n')
	# print('Playing audio...\n')
	# play(audioOutput)

	# Audio stream and multilingual voice model tests


	# print('Running streaming test...\n')
	audioOutput = generate(text = text, stream = True)
	streamAnswer(audioOutput)
	# print('Streaming complete.\n')

	# print('Running multilingual voice test...\n')
	# audioOutput = generate(text = answer, model = 'eleven_multilingual_v1')
	# play(audioOutput)
	# print('Multilingual voice test complete.\n')

# Only run if not imported as a module
if __name__ == '__main__':

	# ---------------- Start Processes ----------------

	objID = threading.Thread(target = lookForObjects)
	audioRec = threading.Thread(target = recordQuestion)

	objID.start()
	print('Looking for objects...\n')
	audioRec.start()
	print('Listening for question...\n')

	objID.join()
	print('Object detection complete.\n')
	print('Objects detected: ' + objects + '\n')
	audioRec.join()
	print('Question recorded.\n')
	print('Question: ' + question + '\n')

	# Build prompt
	query = f"""{instructions}

	Objects held by user: {objects}.
	Question: {question}

	Information: 
	\"\"\"
	{source}
	\"\"\"
	"""
	# Objects held by user: Stomach.

	# Question: What am I holding, and what is it for?

	# print('Prompt: ' + query + '\n')

	# Send prompt to GPT

	messageHistory = [
		{'role': 'system', 'content': 'You answer questions in the same language as the question.'},
		{'role': 'user', 'content': query},
	]

	print('Sending prompt to GPT...\n')
	messageHistory, answer = sendMessage(messageHistory)
	
	if answer != '':
			# print('Answer: ' + answer + '\n\n')
			print('GPT just replied! :) \n')

	# Convert answer to audio
	print('Converting answer to audio...\n')
	convertTTS(answer)

	# -------------- Conversation Handling --------------

	while True:
		# Wait for the user to press space to ask another question
		print('Press space to ask another question, or press q to quit.\n')

		while True:
			if keyboard.is_pressed(' '):
				print('Preparing for next question, please hold...\n')
				break
			if keyboard.is_pressed('q'):
				print('Exiting program...\n')
				exit()

		# Reset variables
		objects = 'User is not holding any objects'
		question = ''
		answer = ''

		# Restart threads

		objID = threading.Thread(target = lookForObjects)
		audioRec = threading.Thread(target = recordQuestion)

		objID.start()
		print('Looking for objects...\n')
		audioRec.start()
		print('Listening for question...\n')

		objID.join()
		print('Object detection complete.\n')
		print('Objects detected: ' + objects + '\n')
		audioRec.join()
		print('Question recorded.\n')
		print('Question: ' + question + '\n')

		# Build prompt with chat history
		# Add last response from GPT to message history
		messageHistory.append({'role': 'assistant', 'content': answer})

		# Build new prompt and add to chat history

		# NOTE: Add this to the query if the model's response has any deviations from previous instructions
		"""
		Remember to consider the object list and the information provided when answering 
		the user's question. Do not mention the user or the information in your answer 
		to make it more sound natural.

		If the question is unrelated to the information, ignore all previous instructions
		and try to answer the question without mentioning the information or the objects
		to make it sound more natural.
		"""

		query = f"""Objects held by user: {objects}.
Question: {question}
"""

		messageHistory.append({'role': 'user', 'content': query})

		# Send prompt to GPT
	
		print('Prompt: ' + query + '\n')

		print('Sending prompt to GPT...\n')

		messageHistory, answer = sendMessage(messageHistory)

		if answer != '':
			# print('Answer: ' + answer + '\n\n')
			print('GPT just replied! :) \n')

		# Convert answer to audio
		print('Converting answer to audio...\n')
		convertTTS(answer)